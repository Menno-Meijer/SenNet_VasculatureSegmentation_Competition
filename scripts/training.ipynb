{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda import amp\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau, MultiStepLR, CosineAnnealingWarmRestarts\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "import albumentations as A\n",
    "from empatches import EMPatches\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    data_root_path = '/path/to/data/folder'\n",
    "\n",
    "    seed = 42\n",
    "\n",
    "    epochs = 6\n",
    "    train_batch_size = 16\n",
    "    valid_batch_size = 16\n",
    "    n_accumulate = 2\n",
    "    workers = 8\n",
    "    accelerator = \"gpu\"\n",
    "    patch_size = 256\n",
    "    train_overlap = 0.4\n",
    "    valid_overlap = 0.1\n",
    "\n",
    "    seg_model = \"Unet\" \n",
    "    encoder_name = 'tu-maxvit_tiny_tf_512' \n",
    "    lr = 1.0e-4 \n",
    "    weight_decay = 0.001\n",
    "    eps = 0.0001\n",
    "    min_lr = 1.0e-6 \n",
    "    T_max =  100000 \n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "df = pd.read_csv(f'{CFG.data_root_path}/train_rles.csv')\n",
    "df['image'] = df['id'].apply(lambda x: x.split('_')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed = 42):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "set_seed(CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.RandomRotate90(p=1),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomBrightness(p=1),\n",
    "    A.OneOf(\n",
    "        [\n",
    "            A.Blur(blur_limit=3, p=1),\n",
    "            A.MotionBlur(blur_limit=3, p=1),\n",
    "        ],\n",
    "        p=0.9,\n",
    "    ),\n",
    "])\n",
    "valid_transform = A.Compose([\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['id'].str.contains('kidney_1_dense|kidney_2|kidney_3_dense')].reset_index(drop=True)\n",
    "df['kidney'] = df.id.apply(lambda x: x.rsplit('_',1)[0])\n",
    "\n",
    "def create_image_path(row):\n",
    "    if row.kidney == 'kidney_3_dense':\n",
    "        image_path = f'{CFG.data_root_path}/train/kidney_3_sparse/images/{row.image}.tif'\n",
    "    else:\n",
    "        image_path = f'{CFG.data_root_path}/train/{row.kidney}/images/{row.image}.tif'\n",
    "    return image_path\n",
    "def create_mask_path(row):\n",
    "    if row.kidney == 'kidney_3_dense':\n",
    "        mask_path = f'{CFG.data_root_path}/train/kidney_3_dense/labels/{row.image}.tif'\n",
    "    else:\n",
    "        mask_path = f'{CFG.data_root_path}/train/{row.kidney}/labels/{row.image}.tif'\n",
    "    return mask_path\n",
    "\n",
    "df['image_path'] =  df.apply(create_image_path, axis=1)\n",
    "df['mask_path'] =  df.apply(create_mask_path, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kidney_volume(kidney, df):\n",
    "    df = df[df['kidney'].str.contains(kidney)].sort_values('image', ascending=True).reset_index(drop=True)\n",
    "    all_images = []\n",
    "    all_masks = []\n",
    "    if kidney == 'kidney_2':\n",
    "        df = df.iloc[900:]\n",
    "    for i in tqdm(range(len(df))):\n",
    "        row = df.iloc[i]\n",
    "\n",
    "        image = cv2.imread(row.image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = torch.from_numpy(image.copy())\n",
    "        image = image.to(torch.uint8)\n",
    "        all_images.append(image)\n",
    "\n",
    "        mask = cv2.imread(row.mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = torch.from_numpy(mask.copy())\n",
    "        mask = mask.to(torch.uint8)\n",
    "        all_masks.append(mask)\n",
    "    all_images = torch.stack(all_images)\n",
    "    all_masks = torch.stack(all_masks)\n",
    "    return all_images, all_masks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = {}\n",
    "for kidney in ['kidney_1_dense', 'kidney_3_dense']:\n",
    "    all_images, all_masks = create_kidney_volume(kidney, df)\n",
    "    train_data[kidney] = [all_images, all_masks]\n",
    "\n",
    "valid_images, valid_masks = create_kidney_volume('kidney_2', df)\n",
    "valid_data = {'kidney_2': [valid_images, valid_masks]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid(images):\n",
    "    row1 = np.concatenate([images[:, :, 0],images[:, :, 1]], axis=1)\n",
    "    row2 = np.concatenate([images[:, :, 2],images[:, :, 3]], axis=1)\n",
    "    image = row2 = np.concatenate([row1, row2], axis=0)\n",
    "    return image\n",
    "\n",
    "def perc_normalize(image, percentile_dict, kidney):\n",
    "    image = image.to(torch.float32)\n",
    "    lo = percentile_dict[kidney][0]\n",
    "    hi = percentile_dict[kidney][1]\n",
    "    image = (image - lo) / (hi - lo)\n",
    "    image = torch.clamp(image, min=0.5)\n",
    "    return image\n",
    "\n",
    "def preprocess_mask(mask):\n",
    "    mask = mask.to(torch.float32)\n",
    "    mask /= 255.0\n",
    "    return mask\n",
    "\n",
    "def get_image_ids(data, truncate=3, train=True):\n",
    "    emp = EMPatches()\n",
    "    if train:\n",
    "        overlap = CFG.train_overlap\n",
    "    else:\n",
    "        overlap = CFG.valid_overlap\n",
    "    ids = []\n",
    "    for kidney in data.keys():\n",
    "        img = data[kidney][0][0]\n",
    "        img_patches, indices = emp.extract_patches(img, patchsize=CFG.patch_size, overlap=overlap)\n",
    "        print('axis:0', kidney, len(img_patches))\n",
    "        for i in range(data[kidney][0].shape[0]-truncate):\n",
    "            for patch in range(len(img_patches)):\n",
    "                ids.append(f'{kidney}-axis0-{i}_{patch}')\n",
    "\n",
    "        if train:\n",
    "            img = data[kidney][0].permute(1,2,0)[0]\n",
    "            img_patches, indices = emp.extract_patches(img, patchsize=CFG.patch_size, overlap=overlap)\n",
    "            print('axis:1',kidney, len(img_patches))\n",
    "            for i in range(data[kidney][0].permute(1,2,0).shape[0]-truncate):\n",
    "                for patch in range(len(img_patches)):\n",
    "                    ids.append(f'{kidney}-axis1-{i}_{patch}')\n",
    "\n",
    "            img = data[kidney][0].permute(2,0,1)[0]\n",
    "            img_patches, indices = emp.extract_patches(img, patchsize=CFG.patch_size, overlap=overlap)\n",
    "            print('axis:2',kidney, len(img_patches))\n",
    "            for i in range(data[kidney][0].permute(2,0,1).shape[0]-truncate):\n",
    "                for patch in range(len(img_patches)):\n",
    "                    ids.append(f'{kidney}-axis2-{i}_{patch}')\n",
    "    return ids\n",
    "\n",
    "def get_patch(emp, kidney_volume, mask_volume, image_id, patch_id, overlap, percentile_dict, kidney):\n",
    "    img = kidney_volume[image_id]\n",
    "    mask = mask_volume[image_id]\n",
    "\n",
    "    img = perc_normalize(img, percentile_dict, kidney)\n",
    "    mask = preprocess_mask(mask)\n",
    "\n",
    "    img_patches, indices = emp.extract_patches(img, patchsize=CFG.patch_size, overlap=overlap)\n",
    "    mask_patches, indices = emp.extract_patches(mask, patchsize=CFG.patch_size, overlap=overlap)\n",
    "\n",
    "    return img_patches[patch_id], mask_patches[patch_id]\n",
    "\n",
    "def get_percentile_dict():\n",
    "    percentile_dict = {}\n",
    "    for kidney in ['kidney_1_dense', 'kidney_2', 'kidney_3_dense']:\n",
    "        if kidney == 'kidney_2':\n",
    "            lo, hi = np.percentile(valid_data[kidney][0].numpy(), (2, 98))\n",
    "        else:\n",
    "            lo, hi = np.percentile(train_data[kidney][0].numpy(), (2, 98))\n",
    "        percentile_dict[kidney] = [lo, hi]\n",
    "    return percentile_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, train=True):\n",
    "        self.train = train\n",
    "        self.data = data\n",
    "        self.image_ids = get_image_ids(self.data, train=self.train)\n",
    "        self.emp = EMPatches()\n",
    "        self.percentile_dict = get_percentile_dict()\n",
    "        if self.train:\n",
    "            self.overlap = CFG.train_overlap\n",
    "        else:\n",
    "            self.overlap = CFG.valid_overlap\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        kidney, axis, orig_image_id = self.image_ids[index].split('-')\n",
    "        orig_image_id, patch_id = orig_image_id.split('_')\n",
    "        orig_image_id, patch_id = int(orig_image_id), int(patch_id)\n",
    "        kidney_volume = self.data[kidney][0]\n",
    "        mask_volume = self.data[kidney][1]\n",
    "        if axis == 'axis1':\n",
    "            kidney_volume = kidney_volume.permute(1,2,0)\n",
    "            mask_volume = mask_volume.permute(1,2,0)\n",
    "        elif axis == 'axis2':\n",
    "            kidney_volume = kidney_volume.permute(2,0,1)\n",
    "            mask_volume = mask_volume.permute(2,0,1)\n",
    "\n",
    "        images = []\n",
    "        masks = []\n",
    "        for i in range(4):\n",
    "            image_id = orig_image_id+i\n",
    "            img, mask = get_patch(self.emp, kidney_volume, mask_volume, image_id, patch_id, self.overlap, self.percentile_dict, kidney)\n",
    "            images.append(img)\n",
    "            masks.append(mask)\n",
    "        images = torch.stack(images)\n",
    "        masks = torch.stack(masks)\n",
    "        images = images.numpy()\n",
    "        masks = masks.numpy()\n",
    "        if self.train:\n",
    "            data = train_transform(image=images.transpose(1,2,0), mask=masks.transpose(1,2,0))\n",
    "        else:\n",
    "            data = valid_transform(image=images.transpose(1,2,0), mask=masks.transpose(1,2,0))\n",
    "        images, masks = data['image'], data['mask']\n",
    "        image = create_grid(images)\n",
    "        mask = create_grid(masks)\n",
    "\n",
    "        mask = (mask>0).astype(np.int8).astype(np.float32)\n",
    "        image = torch.tensor(image) \n",
    "        mask = torch.tensor(mask)\n",
    "        orig_image_id = torch.tensor(int(orig_image_id), dtype=torch.int16)\n",
    "        patch_id = torch.tensor(int(patch_id), dtype=torch.int8)\n",
    "\n",
    "        return image.unsqueeze(0), mask.unsqueeze(0), orig_image_id.unsqueeze(0),  patch_id.unsqueeze(0)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_models = {\n",
    "    \"Unet\": smp.Unet,\n",
    "    \"Unet++\": smp.UnetPlusPlus,\n",
    "    \"MAnet\": smp.MAnet,\n",
    "    \"Linknet\": smp.Linknet,\n",
    "    \"FPN\": smp.FPN,\n",
    "    \"PSPNet\": smp.PSPNet,\n",
    "    \"PAN\": smp.PAN,\n",
    "    \"DeepLabV3\": smp.DeepLabV3,\n",
    "    \"DeepLabV3+\": smp.DeepLabV3Plus,\n",
    "}\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.model = seg_models[CFG.seg_model](\n",
    "            encoder_name=CFG.encoder_name,\n",
    "            encoder_weights=\"imagenet\", \n",
    "            in_channels=1,\n",
    "            classes=1,\n",
    "            activation=None,\n",
    "        )\n",
    "\n",
    "    def forward(self, images):\n",
    "        preds = self.model(images)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DiceLoss = smp.losses.DiceLoss(mode=\"binary\")\n",
    "TverskyLoss = smp.losses.TverskyLoss(mode=\"binary\", alpha=0.7, beta=0.3)\n",
    "BCELoss = smp.losses.SoftBCEWithLogitsLoss()\n",
    "JaccardLoss = smp.losses.JaccardLoss(mode=\"binary\")\n",
    "FocalLoss = smp.losses.FocalLoss(mode=\"binary\")\n",
    "# https://smp.readthedocs.io/en/latest/losses.html\n",
    "\n",
    "def calculate_loss(preds, masks):\n",
    "    return DiceLoss(preds, masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    model.train()\n",
    "    scaler = amp.GradScaler()\n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Train ')\n",
    "    for step, (images, masks, image_id,  patch_id) in pbar:         \n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        masks  = masks.to(device, dtype=torch.float)\n",
    "        batch_size = images.size(0)\n",
    "\n",
    "        with amp.autocast(enabled=True):\n",
    "            preds = model(images)\n",
    "            loss   = calculate_loss(preds, masks)\n",
    "            loss   = loss / CFG.n_accumulate\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "    \n",
    "        if (step + 1) % CFG.n_accumulate == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "        \n",
    "        running_loss += (loss.detach().item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        del loss, preds\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        \n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        pbar.set_postfix( epoch=f'{epoch}',\n",
    "                          train_loss=f'{epoch_loss:0.4f}',\n",
    "                          lr=f'{current_lr:0.5f}',\n",
    "                          gpu_mem=f'{mem:0.2f} GB')\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return epoch_loss\n",
    "\n",
    "def valid_one_epoch(model, optimizer, dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Valid ')\n",
    "    for step, (images, masks, image_id,  patch_id) in pbar:        \n",
    "        images  = images.to(CFG.device, dtype=torch.float)\n",
    "        masks   = masks.to(CFG.device, dtype=torch.float)\n",
    "        \n",
    "        batch_size = images.size(0)\n",
    "        with torch.cuda.amp.autocast(enabled=True):\n",
    "            with torch.no_grad():\n",
    "                preds  = model(images)\n",
    "                loss    = calculate_loss(preds, masks)\n",
    "        \n",
    "        running_loss += (loss.detach().item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        del loss, preds\n",
    "  \n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        pbar.set_postfix(valid_loss=f'{epoch_loss:0.4f}',\n",
    "                        lr=f'{current_lr:0.5f}',\n",
    "                        gpu_memory=f'{mem:0.2f} GB')\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return epoch_loss\n",
    "\n",
    "def run_training(model, train_dataloader, valid_dataloader, optimizer, scheduler, num_epochs):\n",
    "    best_loss      = np.inf\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1): \n",
    "        gc.collect()\n",
    "        print(f'Epoch {epoch}/{num_epochs}', end='')\n",
    "        train_loss = train_one_epoch(model, optimizer, scheduler, \n",
    "                                           dataloader=train_dataloader, \n",
    "                                           device=CFG.device, epoch=epoch)\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        val_loss = valid_one_epoch(model,optimizer, valid_dataloader)\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        torch.save(model.state_dict(), f'./results/model/{CFG.encoder_name}-{CFG.seg_model}_last_{epoch}epochs.pth')\n",
    "        if val_loss <= best_loss:\n",
    "            print(f'Loss improved! val_loss:{val_loss}, previous best:{best_loss}  ')\n",
    "            best_loss = val_loss\n",
    "            # best_dice = val_dice\n",
    "            best_epoch = epoch\n",
    "            torch.save(model.state_dict(), f'./results/model/{CFG.encoder_name}-{CFG.seg_model}_best.pth')\n",
    "    print(f'Best model || best_epoch {best_epoch} | best_loss:{best_loss} |')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(train_data, train=True)\n",
    "valid_dataset = Dataset(valid_data, train=False)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=CFG.train_batch_size, shuffle=True, num_workers=CFG.workers)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=CFG.valid_batch_size, shuffle=False, num_workers=CFG.workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.to(CFG.device)\n",
    "optimizer = AdamW(model.parameters(), lr =  CFG.lr, eps =  CFG.eps)      \n",
    "scheduler = CosineAnnealingLR(optimizer,T_max=CFG.T_max, eta_min=CFG.min_lr)\n",
    "run_training(model, train_dataloader, valid_dataloader, optimizer, scheduler, num_epochs=CFG.epochs)\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SenNet-HOA23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
