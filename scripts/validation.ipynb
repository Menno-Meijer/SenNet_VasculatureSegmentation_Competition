{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "import albumentations as A\n",
    "import joblib\n",
    "from empatches import EMPatches\n",
    "import nibabel as nib\n",
    "import cc3d\n",
    "from scipy.ndimage import median_filter\n",
    "\n",
    "from helper_scripts.surface_dice_score import compute_surface_dice_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    data_root_path = '/path/to/data/folder'\n",
    "\n",
    "    seed = 42\n",
    "\n",
    "    epochs = 10\n",
    "    valid_batch_size = 32\n",
    "    workers = 8\n",
    "    accelerator = \"gpu\"\n",
    "\n",
    "    valid_overlap = 0.1\n",
    "    patch_size = 256\n",
    "\n",
    "    seg_model = \"Unet\" \n",
    "    encoder_name = 'tu-maxvit_tiny_tf_512' \n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "df = pd.read_csv(f'{CFG.data_root_path}/train_rles.csv')\n",
    "df['image'] = df['id'].apply(lambda x: x.split('_')[-1])\n",
    "valid_df = df[df['id'].str.contains('kidney_2')].iloc[900:].reset_index(drop=True)[['id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed = 42):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "set_seed(CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_encode(mask):\n",
    "    pixel = mask.flatten()\n",
    "    pixel = np.concatenate([[0], pixel, [0]])\n",
    "    run = np.where(pixel[1:] != pixel[:-1])[0] + 1\n",
    "    run[1::2] -= run[::2]\n",
    "    rle = ' '.join(str(r) for r in run)\n",
    "    if rle == '':\n",
    "        rle = '1 0'\n",
    "    return rle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_transform = A.Compose([\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['id'].str.contains('kidney_1_dense|kidney_2|kidney_3_dense')].reset_index(drop=True)\n",
    "df['kidney'] = df.id.apply(lambda x: x.rsplit('_',1)[0])\n",
    "\n",
    "def create_image_path(row):\n",
    "    if row.kidney == 'kidney_3_dense':\n",
    "        image_path = f'{CFG.data_root_path}/train/kidney_3_sparse/images/{row.image}.tif'\n",
    "    else:\n",
    "        image_path = f'{CFG.data_root_path}/train/{row.kidney}/images/{row.image}.tif'\n",
    "    return image_path\n",
    "def create_mask_path(row):\n",
    "    if row.kidney == 'kidney_3_dense':\n",
    "        mask_path = f'{CFG.data_root_path}/train/kidney_3_dense/labels/{row.image}.tif'\n",
    "    else:\n",
    "        mask_path = f'{CFG.data_root_path}/train/{row.kidney}/labels/{row.image}.tif'\n",
    "    return mask_path\n",
    "\n",
    "df['image_path'] =  df.apply(create_image_path, axis=1)\n",
    "df['mask_path'] =  df.apply(create_mask_path, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kidney_volume(kidney, df):\n",
    "    df = df[df['kidney'].str.contains(kidney)].sort_values('image', ascending=True).reset_index(drop=True)\n",
    "    all_images = []\n",
    "    all_masks = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        row = df.iloc[i]\n",
    "\n",
    "        image = cv2.imread(row.image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = torch.from_numpy(image.copy())\n",
    "        image = image.to(torch.uint8)\n",
    "        all_images.append(image)\n",
    "\n",
    "        mask = cv2.imread(row.mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = torch.from_numpy(mask.copy())\n",
    "        mask = mask.to(torch.uint8)\n",
    "        all_masks.append(mask)\n",
    "    all_images = torch.stack(all_images)\n",
    "    all_masks = torch.stack(all_masks)\n",
    "    return all_images, all_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_images, valid_masks = create_kidney_volume('kidney_2', df)\n",
    "valid_data = {'kidney_2': [valid_images, valid_masks]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid(images):\n",
    "    row1 = np.concatenate([images[0, :, :],images[1, :, :]], axis=1)\n",
    "    row2 = np.concatenate([images[2, :, :],images[3, :, :]], axis=1)\n",
    "    image = row2 = np.concatenate([row1, row2], axis=0)\n",
    "    return image\n",
    "\n",
    "def preprocess_image(image, lo, hi):\n",
    "    image = image.to(torch.float32)\n",
    "    image = (image - lo) / (hi - lo)\n",
    "    image = torch.clamp(image, min=0.5)\n",
    "    return image\n",
    "\n",
    "def preprocess_mask(mask):\n",
    "    mask = mask.to(torch.float32)\n",
    "    mask /= 255.0\n",
    "    return mask\n",
    "\n",
    "def get_patch_id_list(data, truncate=0, return_indices=False):\n",
    "    emp = EMPatches()\n",
    "    img = data[0]\n",
    "    img_patches, image_indices = emp.extract_patches(img, patchsize=CFG.patch_size, overlap=CFG.valid_overlap)\n",
    "    patch_ids = []\n",
    "    for image_id in range(data.shape[0]-truncate):\n",
    "        for patch in range(len(img_patches)):\n",
    "            patch_ids.append(f'{image_id}_{patch}')\n",
    "    if return_indices:\n",
    "        return patch_ids, len(img_patches), image_indices\n",
    "    return patch_ids\n",
    "\n",
    "def get_percentile_dict():\n",
    "    percentile_dict = {}\n",
    "    for kidney in ['kidney_2']:\n",
    "        if kidney == 'kidney_2':\n",
    "            lo, hi = np.percentile(valid_data[kidney][0].numpy(), (2, 98))\n",
    "        percentile_dict[kidney] = [lo, hi]\n",
    "    return percentile_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, patch_ids, albumentation=False):\n",
    "        self.data = data\n",
    "        self.patch_ids = patch_ids\n",
    "        self.emp = EMPatches()\n",
    "        self.lo, self.hi = np.percentile(data.numpy(), (2, 98))\n",
    "        self.albumentation = albumentation\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        orig_image_id, patch_id = self.patch_ids[index].split('_')\n",
    "        images = []\n",
    "        for i in range(4):\n",
    "            image_id = int(orig_image_id)+i\n",
    "            img = preprocess_image(self.data[image_id], self.lo, self.hi)\n",
    "            img_patches, image_indices = self.emp.extract_patches(img, patchsize=CFG.patch_size, overlap=CFG.valid_overlap)\n",
    "            img = img_patches[int(patch_id)]\n",
    "            images.append(img)\n",
    "        images = np.stack(images)\n",
    "        image = create_grid(images)\n",
    "        if self.albumentation == 'Brightness':\n",
    "            image = A.RandomBrightness(limit=[-0.05,-0.05],p=1)(image=image)['image']\n",
    "        \n",
    "        image = torch.tensor(image)\n",
    "        orig_image_id = torch.tensor(int(orig_image_id), dtype=torch.int16)\n",
    "        patch_id = torch.tensor(int(patch_id), dtype=torch.int8)\n",
    "        return image.unsqueeze(0), orig_image_id.unsqueeze(0),  patch_id.unsqueeze(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patch_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_models = {\n",
    "    \"Unet\": smp.Unet,\n",
    "    \"Unet++\": smp.UnetPlusPlus,\n",
    "    \"MAnet\": smp.MAnet,\n",
    "    \"Linknet\": smp.Linknet,\n",
    "    \"FPN\": smp.FPN,\n",
    "    \"PSPNet\": smp.PSPNet,\n",
    "    \"PAN\": smp.PAN,\n",
    "    \"DeepLabV3\": smp.DeepLabV3,\n",
    "    \"DeepLabV3+\": smp.DeepLabV3Plus,\n",
    "}\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.model = seg_models[CFG.seg_model](\n",
    "            encoder_name=CFG.encoder_name,\n",
    "            encoder_weights=None, \n",
    "            in_channels=1,\n",
    "            classes=1,\n",
    "            activation=None,\n",
    "        )\n",
    "\n",
    "    def forward(self, images):\n",
    "        preds = self.model(images)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.to(CFG.device)\n",
    "weights = torch.load(f'./results/model/tu-maxvit_tiny_tf_512-Unet_loss_V17_last_3epochs.pth', map_location=CFG.device)\n",
    "model.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_grid(images, k=0):\n",
    "    row1 = torch.concat([torch.rot90(images[:,:,:CFG.patch_size, :CFG.patch_size], k=k, dims=[2, 3]), torch.rot90(images[:,:,:CFG.patch_size, CFG.patch_size:], k=k, dims=[2, 3])], axis=3)\n",
    "    row2 = torch.concat([torch.rot90(images[:,:,CFG.patch_size:, :CFG.patch_size], k=k, dims=[2, 3]), torch.rot90(images[:,:,CFG.patch_size:, CFG.patch_size:], k=k, dims=[2, 3])], axis=3)\n",
    "    image = torch.concat([row1, row2], axis=2)\n",
    "    return image\n",
    "\n",
    "def rotate_grid_tta(model, images, rot90):\n",
    "    with torch.cuda.amp.autocast(enabled=True):\n",
    "        with torch.no_grad():\n",
    "            images = rotate_grid(images, k=rot90)\n",
    "            preds_tta = model(images)\n",
    "            preds_tta = nn.Sigmoid()(preds_tta)\n",
    "            preds_tta = rotate_grid(preds_tta, k=-rot90)\n",
    "            return preds_tta\n",
    "        \n",
    "def predict_axis(kidney_volume, all_preds, axis=0, albumentation=False):\n",
    "    emp = EMPatches()\n",
    "    print('Predicting axis:', axis)\n",
    "    if axis == 1:\n",
    "        kidney_volume = kidney_volume.permute(1,2,0)\n",
    "        all_preds = all_preds.transpose(1,2,0)\n",
    "    elif axis == 2:\n",
    "        kidney_volume = kidney_volume.permute(2,0,1)\n",
    "        all_preds = all_preds.transpose(2,0,1)\n",
    "    \n",
    "    kidney_patched_ids, num_patches_kidney, indices_kidney = get_patch_id_list(kidney_volume, truncate=3, return_indices=True)\n",
    "\n",
    "    test_dataset = Dataset(kidney_volume, kidney_patched_ids, albumentation=albumentation)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=CFG.valid_batch_size, shuffle=False, num_workers=CFG.workers,pin_memory=True)\n",
    "    \n",
    "    \n",
    "    kidney_patched_ids = get_patch_id_list(kidney_volume, truncate=0)\n",
    "    test_dict = {}\n",
    "    test_num = {}\n",
    "    for id in kidney_patched_ids:\n",
    "        test_dict[id] = torch.zeros((CFG.patch_size,CFG.patch_size), device='cpu', dtype=torch.float16)\n",
    "        test_num[id] = 0\n",
    "        \n",
    "    pbar = tqdm(enumerate(test_dataloader), total=len(test_dataloader), desc='Test ')\n",
    "    for step, (images, orig_image_id, patch_id) in pbar:        \n",
    "        images  = images.to(CFG.device, dtype=torch.float)\n",
    "        preds = torch.zeros(images.shape, device='cpu')\n",
    "\n",
    "        for i in range(4): \n",
    "            preds_tta = rotate_grid_tta(model, images, i)\n",
    "            preds += preds_tta.detach().cpu()\n",
    "        preds /= 4 \n",
    "        preds = preds.to(torch.float16)\n",
    "        orig_image_id = orig_image_id.cpu().numpy()\n",
    "        patch_id = patch_id.cpu().numpy()\n",
    "        for i, pred in enumerate(preds):\n",
    "            pred = pred.squeeze(0)\n",
    "            patches = torch.stack([pred[:CFG.patch_size, :CFG.patch_size], pred[:CFG.patch_size, CFG.patch_size:], pred[CFG.patch_size:, :CFG.patch_size], pred[CFG.patch_size:, CFG.patch_size:]])\n",
    "            for x, patch in enumerate(patches):\n",
    "                image_id = orig_image_id[i].item()+x\n",
    "                image_patch_id = f'{str(image_id)}_{patch_id[i].item()}'\n",
    "                test_dict[image_patch_id] += patch\n",
    "                test_num[image_patch_id] += 1\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()     \n",
    "    \n",
    "    for id in kidney_patched_ids:\n",
    "        test_dict[id] /= test_num[id]\n",
    "    \n",
    "    print('Adding to predictions:')\n",
    "    for x, image_id in enumerate(tqdm(range(kidney_volume.shape[0]))):\n",
    "        preds_image = []\n",
    "        for i in range(num_patches_kidney):\n",
    "            patch_id = f'{image_id}_{i}'\n",
    "            preds_image.append(test_dict[patch_id].cpu().numpy())\n",
    "            test_dict[patch_id] = 0\n",
    "        merged_preds = emp.merge_patches(preds_image, indices_kidney, mode='avg')\n",
    "        merged_preds = merged_preds.astype(np.float16)\n",
    "        all_preds[x] += merged_preds\n",
    "    \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    print(all_preds.shape)   \n",
    "    if axis == 1:\n",
    "        kidney_volume = kidney_volume.permute(2,0,1)\n",
    "        all_preds = all_preds.transpose(2,0,1)\n",
    "    elif axis == 2:\n",
    "        kidney_volume = kidney_volume.permute(1,2,0)\n",
    "        all_preds = all_preds.transpose(1,2,0)\n",
    "    print(all_preds.shape)\n",
    "        \n",
    "    return all_preds\n",
    "\n",
    "def predict_kidney(kidney='kidney_2', folder='train'):\n",
    "    kidney_volume = valid_data['kidney_2'][0]\n",
    "    all_preds = np.zeros(kidney_volume.shape, dtype=np.float16)\n",
    "    # all_preds = predict_axis(kidney_volume, all_preds, axis=0, albumentation='Brightness')\n",
    "    # all_preds = predict_axis(kidney_volume, all_preds, axis=1, albumentation='Brightness')\n",
    "    # all_preds = predict_axis(kidney_volume, all_preds, axis=2, albumentation='Brightness')\n",
    "\n",
    "    all_preds = predict_axis(kidney_volume, all_preds, axis=0, albumentation=False)\n",
    "    all_preds = predict_axis(kidney_volume, all_preds, axis=1, albumentation=False)\n",
    "    all_preds = predict_axis(kidney_volume, all_preds, axis=2, albumentation=False)\n",
    "    counter = 3\n",
    "    all_preds /= counter\n",
    "    \n",
    "    return all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = predict_kidney()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_surface_dice_score(all_preds, all_orig_masks, threshold):\n",
    "    height = all_orig_masks.shape[1]\n",
    "    width = all_orig_masks.shape[2]\n",
    "    all_preds = (all_preds>threshold).astype(np.int8) \n",
    "\n",
    "    # all_preds = cc3d.dust(\n",
    "    #             all_preds, threshold=16, \n",
    "    #             connectivity=26, in_place=False\n",
    "    #             )\n",
    "    # all_preds = median_filter(all_preds, size=2)\n",
    "    # all_preds, N = cc3d.largest_k(\n",
    "    #                         all_preds, k=10, \n",
    "    #                         connectivity=26, delta=0,\n",
    "    #                         return_N=True,\n",
    "    #                         )\n",
    "    # all_preds = (all_preds >= 2).astype(np.int8)\n",
    "\n",
    "    preds_rle = []\n",
    "    for pred in all_preds:\n",
    "        rle = rle_encode(pred)\n",
    "        preds_rle.append(rle)\n",
    "\n",
    "    labels_rle = []\n",
    "    for pred in all_orig_masks:\n",
    "        rle = rle_encode(pred)\n",
    "        labels_rle.append(rle)\n",
    "    \n",
    "    preds_df = valid_df.copy()\n",
    "    preds_df['rle'] = preds_rle\n",
    "    valid_df['rle'] = labels_rle\n",
    "    valid_df['width'] = width\n",
    "    valid_df['height'] = height\n",
    "    del all_preds, all_orig_masks\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return compute_surface_dice_score(preds_df, valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_surface_dice_score(all_preds, valid_data['kidney_2'][1].numpy(), 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.7402400374412537 0.1\n",
    "# 0.8727735280990601 0.2 --> 0.647912 private score, 13th place solution\n",
    "# 0.8868693709373474 0.3\n",
    "# 0.8942667841911316 0.4 --> 0.591234 private score\n",
    "# 0.8997269868850708 0.5 \n",
    "# 0.9003251194953918 0.6\n",
    "# 0.892861008644104 0.7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = (all_preds>0.5).astype(np.int8) \n",
    "all_preds = nib.Nifti1Image(all_preds, np.eye(4))  \n",
    "nib.save(all_preds, './results/segmentations/all_preds_nifti.nii')\n",
    "all_labels = nib.Nifti1Image(valid_data['kidney_2'][1].numpy(), np.eye(4))  \n",
    "nib.save(all_labels, './results/segmentations/all_labels_nifti.nii')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SenNet-HOA23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
